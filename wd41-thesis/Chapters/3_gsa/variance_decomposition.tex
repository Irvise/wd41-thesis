%********************************************************************
\section{Variance Decomposition}\label{sec:sa_variance_decomposition}
%********************************************************************

Variance-based methods for global sensitivity analysis use variance as the basis to define a measure of input parameter influence on the overall output variation \cite{Cacuci2004}.
In a statistical framework of sensitivity and uncertainty analysis, 
this choice is natural because variance (or standard deviation) is often used as a measure of dispersion or variability in the model prediction \cite{Saltelli2008}.
The  dispersion, in turn, can measure the level precision of the prediction due when the input parameters are considered uncertain.

This section first presents a method to decompose the model output variance into the contributions from the individual variances of the inputs.
Then, two sensitivity measures based on the decomposition are introdiced a method for their estimation is presented.

%--------------------------------------------------------------------
\subsection{High-Dimensional Model Representation}\label{sub:sa_hdmr}
%--------------------------------------------------------------------

Consider once more a mathematical model $f: \bm{x} \in [0,1]^D \mapsto y = f(\bm{x}) \in \mathbb{R}$.
The high-dimensional model representation (HDMR) of $f(\bm{x})$ is a linear combination of functions with increasing dimensionality up to the dimension of $\bm{x}$ \cite{Li2001},
\begin{equation}
	\begin{split}
		f(\bm{x}) = f_o & + \sum_{d_1 = 1}^{D} f_d(x_d) + \sum_{1 \leq d_1 < d_2 \leq D} f_{d_1,d_2} (x_{d_2}, x_{d_1}) + \cdots  \\
	                      & + f_{1,2,\cdots,D} (x_1, x_2, \cdots, x_D)
	\end{split}
\label{eq:sa_hdmr}
\end{equation}
where $f_o$ is a constant.
The representation in Eq.~(\ref{eq:sa_hdmr}) is unique if the following condition \cite{Sobol2001}
\begin{equation}
    \int_{0}^{1} f_{d_1, d_2, \cdots d_i}(x_{d_1}, x_{d_2}, \cdots, x_{d_i}) d_{x_{d_m}} = 0 \,;
		\, \text{for}\quad m = 1,2,\cdots,s
\label{eq:sa_unicity}
\end{equation}
is verified for all $i \in {1, \cdots, D}$ and 
any corresponding ordered combination of dimensions $1 \leq d_1 < d_2 < \cdots < d_i \leq D$ of the input parameter space.

Assume now that $\bm{\mathcal{X}}$ is a random vector of independent and uniform random variables over a unit hypercube
$\{\Omega = \mathbf{x} \, | \, 0 \leq x_i  \leq 1; i = 1,\cdots, D\}$ such that
\begin{equation}
	\mathcal{Y} = f(\bm{\mathcal{X}})
\label{eq:sa_random_function}
\end{equation}
where $\mathcal{Y}$ is a random variable, resulting from the transformation of the random vector $\mathbf{X}$ by the function $f$.
Using Eq.~(\ref{eq:sa_unicity}) to express each term in Eq.~(\ref{eq:sa_hdmr}), it follows that
\begin{equation}
	\begin{split}
		f_o & = \mathbb{E}[\mathcal{Y}] \\
	  f_{d_1}(x_{d_1}) & = \mathbb{E}_{\sim d_1}[\mathcal{Y}|\mathcal{X}_{d_1}] - \mathbb{E}[\mathcal{Y}]\\
    f_{d_1,d_2}(x_{d_1},x_{d_2}) & = \mathbb{E}_{\sim d_1,d_2} [\mathcal{Y}|\mathcal{X}_{d_1}, \mathcal{X}_{d_2}] \\
																 & - \mathbb{E}_{\sim d_1}[\mathcal{Y}|\mathcal{X}_{d_1}] - \mathbb{E}_{\sim e}[\mathcal{Y}|\mathcal{X}_{d_2}] - \mathbb{E}[\mathcal{Y}] 
	\end{split}
\label{eq:sa_conditional_expectation}
\end{equation}

The same follows for higher-order terms in the decomposition. 
In Eq.~(\ref{eq:sa_conditional_expectation}),
$\mathbb{E}_{\sim \circ} [Y|\circ]$ is a conditional expectation operator,
where subscript symbol $\sim\circ$ in the subscript means that integration on the parameter space is carried out over all parameters except the one(s) in the subscript.
For instance, $\mathbb{E}_{\sim 1} [\mathcal{Y}|\mathcal{X}_1]$ refers to the conditional mean of $\mathcal{Y}$ given $\mathcal{X}_1$, and the integration is carried out for all possible values of parameters in $\mathbf{x}$ except $x_1$.
Note that because $\mathcal{X}_1$ is a random variable, the expectation conditioned on it is also a random variable.

Assuming that $f$ is square integrable, applying the variance operator on $\mathcal{Y}$ results in
\begin{equation}
	\begin{split}
		\mathbb{V}[\mathcal{Y}] = \sum_{d_1=1}^{D} \mathbb{V}[f_{d_1} (x_{d_1})] & + \sum_{1 \leq d_1 < d_2 \leq D} \mathbb{V} [f_{d_1,d_2} (x_d_1, x_d_2)] + \cdots \\
	                                                       & + \mathbb{V} [f_{1,2,\cdots,D} (x_1, x_2, \cdots, x_D)]
		\end{split}
\label{eq:sa_variance_decomposition}
\end{equation}

%------------------------------------------------------------------
\subsection{Sobol' Sensitivity Indices}\label{sub:sa_sobol_indices}
%------------------------------------------------------------------

Division by $\mathbb{V}[Y]$ aptly normalizes Eq.~(\ref{eq:sa_variance_decomposition}):
\begin{equation}
  1 = \sum_{d = 1}^{D} S_d + \sum_{1 \leq d < e \leq D} S_{d,e} + \cdots + S_{1,2,\cdots,D}
\label{eq:sa_normalized_variance}
\end{equation}

The Sobol' main-effect sensitivity index $S_d$ is defined as,
\marginpar{the main-effect index}
\begin{equation}
  S_d = \frac{\mathbb{V}_d [\mathbb{E}_{\sim d} [Y|X_d]]}{\mathbb{V}[Y]}
\label{eq:sa_main_effect_index}
\end{equation}
The numerator is the variance of the conditional expectation,
and the index is a global sensitivity measure interpreted as the amount of variance reduction in the model output if the parameter $X_d$ is fixed (i.e., its variance is reduced to zero).
The main-effect sensitivity index is also known in the literature as the \emph{first-order} sensitivity index 
as it captures only the effect of a single parameter variation on the model output without considering any interaction with other parameters \cite{Saltelli2002}.

A closely related sensitivity index proposed by Homma and Saltelli \cite{Homma1996} is the Sobol' total-effect index defined as,
\marginpar{the total-effect index}
\begin{equation}
  \begin{split}
    ST_{d} & = \frac{\mathbb{E}_{\sim d}[\mathbb{V}_{d}[Y|\mathbf{X}_{\sim d}]]}{\mathbb{V}[Y]}
           & = \frac{\mathbb{V}[Y] - \mathbb{V}_{\sim d}\left[\mathbb{E}_{d}\left[Y|\mathbf{X}_{\sim d}\right]\right]}{\mathbb{V}[Y]} \\
           & = 1 - \frac{\mathbb{V}_{\sim d}[\mathbb{E}_{d}[Y|\mathbf{X}_{\sim d}]}{\mathbb{V}[Y]}
  \end{split}
\label{eq:sa_total_effect_index}
\end{equation}
The index, also a global sensitivity measure, can be interpreted as the amount of variance left in the output if the values of all input parameters, 
\emph{except} $x_d$, can be fixed.

These two sensitivity measures can be related to the objectives of global SA for model assessment as proposed by Saltelli et al \cite{Saltelli2004,Saltelli2008}.
\marginpar{parameter prioritization objective}
The main-effect index is relevant to parameter prioritization in the context of identifying the most influential parameter 
since fixing a parameter with the highest index value would, \emph{on average}, lead to 
the greatest reduction in the output variation.

The total-effect index, on the other hand, is relevant to parameter fixing (or screening) in the context of identifying the least influential set of parameters since fixing any parameter that has a very small 
\marginpar{parameter screening objective}
total-effect index value would not lead to significant reduction in the output variation.
The use of the total-effect index to identify which parameter can be fixed or excluded is similar to that of the elementary effect statistics of the Morris method, 
albeit more exact but also more expensive to compute.
And finally, the difference between the two indices of a given parameter (Eqs.~(\ref{eq:sa_total_effect_index}) and (\ref{eq:sa_main_effect_index})) is used to quantify the amount of all interactions involving that parameters in the model output.

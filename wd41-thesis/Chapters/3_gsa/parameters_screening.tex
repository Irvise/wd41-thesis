%****************************************************************
\section{Parameters Screening}\label{sec:sa_parameters_screening}
%****************************************************************

Screening methods are used to rank the importance of the model parameters using a relatively small number of model evaluations \cite{Saltelli2004}.
However, they tend to simply give qualitative measures.
That is, meaningful information resides in the rank itself but not in the exact importance of the parameters with respect to the output. 
Screening is particularly valuable in the early phase of a SA to identify the noninfluential parameters of a model,
which then could be safely excluded from further detailed analysis. 
This step is important to reduce the size of the problem especially if more expensive methods are to be applied at the subsequent steps. 
In this work, attention was paid to a particular screening method proposed by Morris \cite{Morris1991} with an extension proposed by Campolongo et al. \cite{Campolongo2011}.

%----------------------------------------------------------------------------
\subsection{Elementary Effects and One-at-a-Time Design}\label{sub:sa_ee_oat}
%----------------------------------------------------------------------------

% Elementary effect definition
Consider a mathematical model $f: \bm{x} \in [0,1]^D \mapsto y = f(\bm{x}) \in \mathbb{R}$, 
where $\bm{x} = (x_1, x_2, \dots,x_D)$ is a vector of input parameters.
The elementary effect of the $d$-th parameter on $f$ is defined as
\marginpar{Elementary effect}
\begin{equation}
  EE_d = \frac{f(x_1, \dots, x_d+\Delta,\dots,x_D) - f(x_1, \dots, x_d,\dots,x_D)}{\Delta}
\label{eq:elementary_effect}
\end{equation}
or more concisely,
\begin{equation}
  EE_d = \frac{f(\bm{x} + \Delta \cdot \bm{e}_d) - f(\bm{x})}{\Delta}
\label{eq:elementary_effect_concise}
\end{equation}
where $\bm{e}_d$ is the $d$-th basis vector of the input parameter space;
and $\Delta$, the grid jump, is chosen such that $\mathbf{x} + \Delta \cdot \bm{e}_d$ is still in the specified domain of the parameter space, i.e., $[0,1]^D$; 
$\Delta$ is a value in $\{\frac{1}{p-1}, \dots, 1 - \frac{1}{p-1}\}$, 
where $p$ is the number of (discretization) levels that partition the model parameter space into a uniform grid of points where the model can be evaluated. 
For a given $p$, the grid constructs a finite distribution of $p^{D-1}[p - \Delta(p-1)]$ elementary effects for each input parameter.

% OAT Experimental Design
The elementary effect distributions for each of the input parameters,
evaluated across discretized input parameter space, 
\marginpar{\Glsfirst[hyper=false]{oat} experimental design}
provide useful information on the importance of a parameter on the output.
Unfortunately, an exhaustive evaluation of all elementary effects for a given discretization levels suffers from a curse of dimensionality especially for numerous parameters or for reasonably fine discretization level\footnote{for $p = 8$ and $D = 20$ the total number of evaluations for exhaustive computation of all $EE$s is $\approx 6 \times 10^{17}$ for each parameter}.
Consequently, a class of design of experiment that only change one parameter at a time (\gls[hyper=false]{oat}) are devised to estimate the statistics of the distributions.
  
% Trajectory OAT Design
The key idea behind the original Morris method is in initiating the model evaluations from various \textit{nominal} points, $\bm{x}$,
\marginpar{Trajectory \glsentryshort{oat} design}
randomly selected over the grid and then gradually advancing one grid jump, perturbing one parameter at a time,
making a perturbed point as the base point for the next perturbation.
The order of perturbation (i.e., which dimension to perturb first) and the direction of the perturbation (i.e., whether it is added or subtracted) are also randomized between replications.
As such, different replication generates different starting nominal point as well as different order and sign (but with the same size) of perturbation.
The \gls[hyper=false]{oat} experimental design complemented with this requirement is known as the trajectory design \cite{Ruano2012}.
Fig.~\ref{fig:ch3_plot_oat_illustration_1} illustrates a trajectory design with $4$ replications in a two-dimensional input parameter space discretized in $6$ levels .
\normdoublefigure[pos=tbhp,
                  mainlabel={fig:ch3_plot_oat_illustration},
                  maincaption={Illustration of One-at-a-Time (OAT) design constructed using trajectory scheme (left) and radial scheme (right) each with 4 replications. The trajectory design is discretized in 6 levels, while the number of levels is irrelevant for radial design. Filled circles are the nominal or the starting point (for the trajectory) or the base (for the radial) points and crosses are the perturbed levels.},%
									mainshortcaption={Illustration of One-at-a-Time (OAT) design using trajectory and radial schemes.},
                  leftopt={width=0.45\textwidth},
                  leftlabel={fig:ch3_plot_oat_illustration_1},
                  leftcaption={Trajectory scheme},
                  %leftshortcaption={},%
                  rightopt={width=0.45\textwidth},
                  rightlabel={fig:ch3_plot_oat_illustration_2},
                  rightcaption={Radial scheme},
                  %rightshortcaption={},
                  %spacing={\hfill}
                 ]
{../figures/chapter3/figures/plotOATIllustration_1}
{../figures/chapter3/figures/plotOATIllustration_2}

To remove the requirement to specify a method-specific parameter $p$ (the number of levels),
\marginpar{Radial \glsentryshort{oat} design}
Campolongo et al.\cite{Campolongo2011} proposed to use a radial scheme coupled with Sobol' quasirandom sequence.
In a single replication of this particular OAT design, 
each parameter is perturbed relative to a \textit{base/nominal} point 
which is not required to be located on a predetermined grid.
The size and sign of the perturbation is also allowed to vary from parameter to parameter in different replication.
As such, radial design implicitly incorporates several additional possible sources of variation in the method 
that can potentially bias the estimation of elementary effects.
Because the size of parameter perturbations varies, the definition of the elementary effects is slightly changed to
\marginpar{Elementary effect for radial design}
\begin{equation}
EE_d = \frac{f(\bm{x} + \Delta x_d \cdot \bm{e}_d) - f(\bm{x})}{\Delta x_d}
\end{equation}
where now each parameter at each design replication has its corresponding perturbation size $\Delta x_d \in [-1,1]$ such that $x_d + \Delta x_d \in [0,1]$.

An illustration of a radial design in a two-dimensional input parameter space with $4$ nominal/base points is shown in Fig.~\ref{fig:ch3_plot_oat_illustration_2}.
 
%-------------------------------------------------------------------------------------------------
\subsection{Statistics of Elementary Effects and Sensitivity Measures}\label{sub:sa_ee_statistics}
%-------------------------------------------------------------------------------------------------

% Mean of the elementary effects
Consider now that an $N_R$ number of elementary effects associated with the $d$-th parameter have been sampled from the finite distribution of $EE_d$,
using an \gls[hyper=false]{oat} design with $N_R$ replications, either based on the trajectory or radial design.
The statistical summary of the sampled $EE_d$ based on a given number of an OAT design replications can be calculated.
The first is the arithmetic mean defined as,
\marginpar{Mean of the (sampled) elementary effects}
\begin{equation}
	\mu_d = \frac{1}{N_R} \sum_{r = 1}^{N_R} EE^r_d
	\label{eq:sa_morris_mu}
\end{equation} 
where $EE^r_d$ is the elementary effect of the $d$-th parameter of the $r$-th replication.
The mean gives the global influence of the $d$-th parameter on the chosen output $f$.

% Standard deviation of the elementary effects
The second statistical summary of interest is the standard deviation of the (sampled) elementary effects for input parameter $x_d$,
\marginpar{Standard deviation of the (sampled) elementary effects}
\begin{equation}
	\sigma_d = \sqrt{\frac{1}{N_R} \sum_{r = 1}^{N_R} (EE^r_d - \mu_d)^2}
	\label{eq:sa_morris_sd}
\end{equation} 
The standard deviation gives an indication of the presence of nonlinearity or interactions between the $d$-th input parameter and the others.

% Mean of absolute values of the elementary effects
In cases where $f$ is a non-monotonic function,
the sign of $EE_d$ may change according to the change of the output,
and cancellation effects on the estimation of $\mu_d$ might occur .
To circumvent this issue,
Campolongo et al.~\cite{Campolongo2011} proposed to take the absolute values of the sampled elementary effects.
It is defined as,
\marginpar{Mean of the (sampled) absolute elementary effects}
\begin{equation}
	\mu^*_d = \frac{1}{N_R} \sum_{r = 1}^{N_R} |EE^r_d|
	\label{eq:sa_morris_mustar}
\end{equation}
Note that although the overall sign of the output perturbation is lost by using this measure,
its use is justified if the input parameters are to be ranked based on a single importance measure.

% Interpretation and importance classification
The aforementioned statistical summaries, when evaluated over a large number of replications $N_R$,
can provide global sensitivity measures of the importance of each input parameter.
\marginpar{Input parameter importance classification}
As indicated by Morris \cite{Morris1991}, there are three possible categories of parameter importance based on those statistics:
\begin{enumerate}
	\item Parameters with noninfluential effects on the model output, i.e., the parameters that have relatively small values of both $\mu_d$ (or $\mu^*_d$) and $\sigma_d$.
	\item Parameters with linear or additive effects, i.e., the parameters that have relatively large value of $\mu_d$ (or $\mu^*_d$) and relatively small value of $\sigma_d$.
	The small value of $\sigma_d$ and the large value of $\mu_d$ (or $\mu^*_d$) indicate that the variation of elementary effects across replications is small while the magnitude of the effect itself is consistently large for the perturbations in the parameter space.
	\item Parameters with nonlinear or interaction effects, i.e., the parameters that have a relatively small value of $\mu_d$ (or $\mu^*_d$) and a relatively large value of $\sigma_d$.
	Opposite to the previous case, a small value of $\mu_d$ (or $\mu^*_d$) indicates that the aggregate effect of perturbation is relatively small (or in the case of $\mu_d$, can be close to zero) while a large value of $\sigma_d$ indicates that the variation of the effect is large; the effect can be large or negligibly small depending on the values of the other parameters at which the model is evaluated.
	Such large variation is a symptom of nonlinear effects or parameter interaction.
\end{enumerate}

% Classification and qualitative measure
This classification makes parameter importance ranking and, in turn, screening of noninfluential parameters possible.
However, the procedure is done rather qualitatively, and this is illustrated in Fig.~\ref{fig:ch3_importance_classification}, 
which depicts a typical parameter classification derived from a visual inspection of the elementary effects statistics on the $\sigma$ vs. $\mu^*$ plane.
The notions of influential and noninfluential parameters are based on the relative locations of those statistics in the plane.
Typically, the noninfluential ones are clustered closer to the origin (relative to the more influential ones) with a pronounced boundary such as the situation depicted in Fig.~\ref{fig:ch3_importance_classification}. 
Admittedly, if these statistics are spread somewhat uniformly across the plane, 
the distinction would be more ambiguous and problematic\footnote{In such a case, more advanced classification approaches such as the ones based on clustering techniques might be helpful to identify a finer structure of the parameters importance.}.
Furthermore, for a parameter with a large value of both $\mu^*$ and $\sigma$,
the method cannot distinguish between nonlinearity effect from parameter interaction effect on the output.

\begin{figure}[bth]
	\centering
	\includegraphics[scale=0.80]{../figures/chapter3/figures/importance_classification}
	\caption[Illustration of a typical parameter importance classification based on Morris screening method]{Illustration of a typical parameter importance classification obtained from the Morris screening method. The importance of each parameter relative to the other ones is defined with respect to its location on the $\sigma - \mu^*$ plane. Each dot represents a parameter, and the line corresponds to twice the standard error of the mean (SEM) indicating the relative magnitude of the standard deviation to the mean.}\label{fig:ch3_importance_classification}
\end{figure}

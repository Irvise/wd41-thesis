%**********************************************************************************************************
\section[Diagnosing MCMC Samples]{Diagnosing \gls[hyper=false]{mcmc} Samples}\label{sec:bc_mcmc_diagnostic}
%**********************************************************************************************************

% Opening paragraph
Consider once more Eq.~(\ref{eq:ch5_markov_chain_clt}), the central limit theorem (CLT) for the \gls[hyper=false]{mcmc}.
Let $\{\bm{\mathcal{X}}^{(i)}\}_{i=1}^{I}$ be a stationary Markov chain of length $I$ with a stationary distribution $\pi_t$ (i.e., the target distribution).
Furthermore, it is used to estimate the expectation of a function $f$ under $\pi_t$ such that $\hat{f} = 1/I \sum_i f(\bm{\mathcal{X}}^{(i)})$,
then the asymptotic error of the estimator follows
\begin{equation*}
  \lim_{I \rightarrow \infty} \,\, \hat{f} - \mathbb{E}_{\pi_t}[f] \thicksim \mathcal{N} \left(0, \frac{\sigma_f^2}{I}\right)
\end{equation*}
Where $\sigma^2_f$ is the variance of a given function $f$ evaluated under the stationary density of the chain.
As mentioned, by construction, the successive realizations in a Markov chain is not independent.
Before discussing the implication of this correlation on statistical error of an estimator given above (i.e., $\frac{\sigma^2_f}{I}$) in Section~\ref{sub:bc_mcmc_thinning}, several important concepts are first introduced. 
Note that the dependence on $\pi_t$ in the discussion below has been implicitly assumed and thus suppressed from the notation.

% Autocovariance
The autocovariance of the function $f$ is defined as the covariation between the function $f$ evaluated using the chain at the iteration $i$ and iteration $j$.
That is,
\begin{equation}
  \text{Cov}\left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(j)}) \right] \equiv \mathbb{E}\left[\left(f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right) \cdot \left(f[\bm{\mathcal{X}}^{(j)}]  - \mathbb{E}[f] \right) \right]
\label{eq:ch5_autocovariance}
\end{equation}
Assuming a stationary chain, the covariance becomes only a function of the separation between the two iterations irrespective at which particular point in the chain the function is evaluated.
In other words,
\begin{equation}
  \text{Cov}\left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(i+t)}) \right] \equiv C_f(t) 
\label{eq:ch5_autocovariance_function}
\end{equation}
where $C_f$ is the autocovariance function of $f$ and $t$, the separation between iterations, is called the \emph{lag} of the covariance function.
Note that according to the notation above the covariance function $C_f$ is always defined with respect to a given function $f$, as indicated in the subscript.
Such function includes identity functions that returns a particular dimension of a multivariate chain, e.g., $f(\bm{\mathcal{X}}^{(i)}) = \mathcal{X}^{(i)}_d$, with $d$ the dimension of the multivariate chain.

% Autocorrelation
The autocorrelation function $\rho_f$ of $f$ is the normalized autocovariance function defined as,
\begin{equation}
  \rho_f (t) \equiv \frac{C_f(t)}{C_f(0)}
\label{eq:ch5_autocorrelation}
\end{equation}
where $C_f(0)$ is the lag-$0$ autocovariance and is equal to the process variance $\mathbb{V}[f]$ for a stationary process.

% Some illustration
Autocovariance (and autocorrelation) measures the strength of the covariance (and correlation) between samples in a Markov chain.
By definition both functions are symmetric about the origin.
They also tend to decay with increasing lag as illustrated in the figure below for autocorrelation function of three different Markov chains with different autocorrelation functions.
\normdoublefigure[pos=tbhp,
                  mainlabel={fig:ch5_plot_illustrate_acf},
                  maincaption={Illustration of autocorrelation functions for three different Markov chains. The Markov chain at the top has the strongest autocorrelation shown as solid line in the right plot. The correlation between samples dies off much longer than the other two chains.},%
									mainshortcaption={Illustration of autocorrelation functions for three different Markov chains.},
                  leftopt={width=0.45\textwidth},
                  leftlabel={fig:ch5_plot_illustrate_acf_1},
                  leftcaption={Three different Markov chains},
                  %leftshortcaption={},%
                  rightopt={width=0.45\textwidth},
                 rightlabel={fig:ch5_plot_illustrate_acf_2},
                  rightcaption={Autocorrelation functions as function of lag $t$},
                  %rightshortcaption={},
                  %spacing={\hfill}
                 ]
{../figures/chapter5/figures/plotIllustrateACF_1}
{../figures/chapter5/figures/plotIllustrateACF_2}

%--------------------------------------------------------------------------------------------------------------------------------
\subsection[Autocorrelation in Equilibrium and Thinning]{Autocorrelation in Equilibrium and Thinning}\label{sub:bc_mcmc_thinning}
%--------------------------------------------------------------------------------------------------------------------------------

Assuming that the stationary chain has been attained the asymptotic results of Eq.~(\ref{eq:ch5_markov_chain_clt}) applies.
To derive the expression for $\sigma^2_f$ in the equation, consider that the variance of the \gls[hyper=false]{mcmc} estimator $\hat{f}$ for the expected value of $f$ computed by a Markov chain $\{\bm{\mathcal{X}}^{(i)}\}$ of length $I$ is given by,
\begin{equation}
  \mathbb{V}[\,\hat{f}\,] = \mathbb{E}\left[\left(\frac{1}{I} \sum_{i=1}^I \left( f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right)\right)^2 \right]
\label{eq:ch5_markov_chain_estimate_variance}
\end{equation}
by using nested sum, the definition can be rewritten as,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & = \mathbb{E}\left[\frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \left(f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right) \cdot \left(f[\bm{\mathcal{X}}^{(j)}]  - \mathbb{E}[f] \right) \right] \\
  & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \mathbb{E}\left[\left(f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right) \cdot \left(f[\bm{\mathcal{X}}^{(j)}]  - \mathbb{E}[f] \right) \right] \\
  & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \text{Cov} \left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(j)}) \right]
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_nested_sum}
\end{equation*}
where the definition of covariance between two random variables have been applied to arrive to the last line above.

Assuming that the chain $\{\bm{\mathcal{X}}^{(i)}\}$ is stationary then the covariance function is simply a function of the separation between the two iterations $i$ and $j$,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & =  \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \text{Cov} \left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(j)}) \right] \\
                          & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I C_f (|i - j|) \\
                          & \approx \frac{1}{I^2} \sum_{i=1}^I \sum_{t = -\infty}^{\infty} C_f (|t|) = \frac{1}{I} \sum_{t = -\infty}^{\infty} C_f (|t|)
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_stationary}
\end{equation*}
where $C_f$ is the (stationary) autocovariance function associated with function $f$.
The approximation in the last line above is valid assuming that $C_f$ decays as the separation $t = i - j$ becomes larger \cite{Sokal1997}.
Noting that the covariance function $C_f$ is a symmetric function about zero,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & = \frac{1}{I} \left( C_f (0) + 2 \sum_{t = 1}^{\infty} C_f (t) \right) \\
                          & = \frac{2 C_f (0)}{I} \left( \frac{1}{2} + \sum_{t = 1}^{\infty} \rho_f (t) \right)
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_expand}
\end{equation*}
where $\rho_f$ is the autocorrelation function of $f$ defined in Eq.~(\ref{eq:ch5_autocorrelation}).
Rearranging the term, the variance of the \gls[hyper=false]{mcmc} estimator $\hat{f}$ is given by,
\begin{equation}
  \mathbb{V}[\,\hat{f}\,] = \frac{2 \tau_{\text{int},f}}{I} C_f (0) 
\label{eq:ch5_markov_chain_estimator_variance}
\end{equation}
where $\tau_{\text{int},f}$, the \emph{integrated autocorrelation time} (or simply autocorrelation time), is defined as,
\marginpar{Integrated autocorrelation time}
\begin{equation}
  \tau_{\text{int},f} =  \frac{1}{2} + \sum_{t = 1}^{\infty} \rho_f (t)
\label{eq:ch5_markov_chain_autocorrelation_time}
\end{equation}

In making connection with Eq.~(\ref{eq:ch5_markov_chain_clt}), Eq.~(\ref{eq:ch5_markov_chain_estimator_variance}) can be interpreted in one of two ways.
\marginpar{Effective sample size}
First, the use of Markov chain of length $I$ to estimate the integral of $f$ inflates the true variance of $f$ (i.e., $C_f(0)$) by factor $2 \tau_{\text{int},f}$ in the computation of the \gls[hyper=false]{mc} sampling variance.
In other words, $\sigma^2_f \equiv 2 \tau_{\text{int},f} C_f(0)$.
Or, equivalently, the number of independent samples required in the computation of the \gls[hyper=false]{mc} sampling variance is only a factor of $\frac{1}{2 \tau_{\text{int},f}}$ of the total \gls[hyper=false]{mcmc} samples $I$.
In other words, $N \equiv \frac{I}{2 \tau_{\text{int},f}}$ with $N$ the number of independent samples (or \emph{effective sample size}).
From this latter interpretation, the autocorrelation time refers to the number of \gls[hyper=false]{mcmc} iterations required to generate a single independent sample.

% Autocorrelation time and the length of the chain
In either interpretation, the statistical error associated with the \gls[hyper=false]{mc} estimation is larger for an estimation using \gls[hyper=false]{mcmc} samples than using independent samples due to the inherent correlation.
\marginpar{Determining the length of a chain}
Moreover, in the case of \gls[hyper=false]{mcmc}, the autocorrelation time $\tau_{\text{int},f}$ directly affects the statistical error.
As such, this quantity is useful in either determining the required length of the chain in a \gls[hyper=false]{mcmc} simulation or assessing the statistical error for chain of a given length.
That is, the (required) relative statistical error $\epsilon$ of an estimator $\hat{f}$ is related to the length of the chain through \cite{Akeret2013},
\begin{equation}
  \left(\frac{\mathbb{V}[\hat{f}]}{C_f(0)}\right)^{0.5} = \left(\frac{\mathbb{V}[\hat{f}]}{\mathbb{V}[f]}\right)^{0.5} = \left(\frac{2\tau_{\text{int},f}}{I}\right)^2 \leq \epsilon \Leftrightarrow I \geq \frac{2\tau_{\text{int},f}}{\epsilon^2} 
\label{eq:ch5_markov_chain_relative_error}
\end{equation}
where $I$ is the number of iterations \emph{and} samples for a single particle \gls[hyper=false]{mcmc}.
For an ensemble sampler the number of iterations should be multiplied by the number of walkers $L$ such that,
\begin{equation}
  I \geq \frac{2\,\tau_{\text{int},f}}{\epsilon^2\,L} 
\label{eq:ch5_markov_chain_relative_error_ensemble}
\end{equation}
Note that the autocorrelation time is associated with a given function $f$ and have to be computed for different choice of $f$.
For each, autocorrelation time (and the associated statistical error) gives a sense of scale on the length of an \gls[hyper=false]{mcmc} simulation.
For instance, $10'000$ \gls[hyper=false]{mcmc} iterations are relatively long for a single particle chain having autocorrelation time of $5$ ($\epsilon \approx 3\%)$, but much shorter in comparison for a chain with autocorrelation time of $100$ ($\epsilon \approx 14\%)$.
In the latter case, in such a relatively short chain, the reliability of the estimation of the autocorrelation time itself can actually become a suspect. 

% Estimating Autocovariance function
The autocovariance function of $f$ can be estimated from a realization of a Markov chain $\{\bm{\mathbf{x}}^{(i)}\}_{i=1}^{I}$ using the following estimator \cite{Sokal1997,Akeret2013},
\marginpar{Estimating autocorrelation time}
\begin{equation}
  \hat{C}_f (t) =  \frac{1}{I - t} \sum_{t = 1}^{I - t} (f(\mathbf{x}^{(i)}) - \bar{f}) \, (f(\mathbf{x}^{(i+t)}) - \bar{f})
\label{eq:ch5_markov_chain_autocovariance_function_estimator}
\end{equation}
where $\bar{f} = 1/I \sum_{i} f(\mathbf{x}^{(i)})$ is the sample mean of $f$.
The autocorrelation function estimator follows,
\begin{equation}
  \hat{\rho}_f (t) =  \frac{\hat{C}_f(t)}{\hat{C}_f(0)}
\label{eq:ch5_markov_chain_autocorrelation_function_estimator}
\end{equation}
Finally, the estimator for autocorrelation time is given by,
\begin{equation}
  \hat{\tau}_{\text{t},f} =  \frac{1}{2} + \sum_{t = 1}^{I} \hat{\rho}_f (t)
\label{eq:ch5_markov_chain_autocorrelation_time_estimator}
\end{equation}
Direct estimation of the autocorrelation time using the above estimator is usually unstable due to the statistical noise associated with large lag $t$.
For a large $t$, the data of iterations that are far separated becomes sparser to have a reliable estimate of the autocovariance function value. 
A ``windowing'' technique is proposed in \cite{Sokal1997} to stabilize the estimation and is implemented in the routine \texttt{ACOR} \cite{Goodman2009,Foreman-Mackey2014} used in this thesis.

% On thinning
The notion of independent samples (or effective sample size) mentioned above are coupled with the practice of \emph{thinning} or sub-sampling the \gls[hyper=false]{mcmc} samples \cite{Geyer1992}.
\marginpar{On thinning the chain}
Thinning the chain means that only $1$ \gls[hyper=false]{mcmc} sample is kept for every $k$ iterations, with $k$ an integer.
Often, the integer $k$ is chosen to be close to, or at least the same order of magnitude to, the autocorrelation time $\tau_{\text{int},f}$.
Historically, thinning is mainly motivated by the limited storage and memory to store all the samples, especially for a long running \gls[hyper=false]{mcmc} simulation.
As the end purpose of conducting \gls[hyper=false]{mc} estimation requires the use of independent samples, it was argued that by thinning, only samples that matters (i.e., independent) are kept for further analysis.

On the other hand, the practice of thinning is questioned by several authors \cite{Geyer1992,Link2011}.
The argument against thinning is relatively easy to intuit.
By conducting thinning the autocorrelation in the samples can be reduced thus reducing the statistical error of the estimate.
At the same time, there would be much smaller number of samples after thinning that often off-set the reduction of the error by a smaller autocorrelation time.
 
Thinning can be justified for the purpose of estimating the statistical error of an estimate using the thinned \gls[hyper=false]{mcmc} samples without the need to estimate $\tau_{\text{int},f}$.
It can also be useful in the case expensive ``post-processing'' of the \gls[hyper=false]{mcmc} samples.
That is, if the function $f$ is expensive to evaluate.
For example, in the context of Bayesian data analysis, the posterior samples obtained via \gls[hyper=false]{mcmc} simulation might need to be propagated through a computationally expensive code for the purpose of forward uncertainty quantification by an ordinary \gls[hyper=false]{mc} simulation.
In this case, only calculations of a few samples might be afforded and, as required by \gls[hyper=false]{mc} simulation, such selection of samples should be independent of each other which, in turn, can be achieved by thinning the chain first. 

%-----------------------------------------------------------------------------------------------------------------
\subsection[Initialization Bias and Burn-in]{Initialization Bias and Burn-in}\label{sub:bc_mcmc_diagnostic_burnin}
%-----------------------------------------------------------------------------------------------------------------

% Opening paragraph, why there is
The results above hold for \gls[hyper=false]{mcmc} samples obtained from a stationary chain.
As illustrated in Fig.~\ref{fig:ch5_plot_aies_walker_ensemble_1}, starting an \gls[hyper=false]{mcmc} simulation from an arbitrary starting point causes the exploration in a less typical part of the parameter space (as dictated by the posterior \gls[hyper=false]{pdf}).
In other words, the resulting \gls[hyper=false]{mcmc} samples are taken from a lower probability region of the target probability distribution and thus are less representative of the distribution.
After some period, however, the apparent ``initial transient'' eventually dies off and the chain settles in more typical region of the parameter space.
The colloquial term \emph{burn-in} period is used to characterized this initial part of the chain.
By \emph{burn-in} the chain, it means that the samples corresponding to that period is discarded from further analysis.

% Consequence of burn-in period
As opposed to the previous discussion on autocorrelation in equilibrium that causes inflation of \gls[hyper=false]{mc} \emph{statistical error},
\marginpar{Initialization bias}
the presence of burn-in period in an \gls[hyper=false]{mcmc} simulations coupled with relatively short iterations compared to the length of the burn-in period cause a \emph{systematic bias} on the \gls[hyper=false]{mc} estimator \cite{Sokal1997}.
Therefore, for a chain of a finite length, it is important to determine the length of burn-in period lest the estimator will be heavily affected by initialization bias.
In a single particle \gls[hyper=false]{mcmc} algorithm determining the burn-in length is less of an issue as the total number of iterations tends to be much larger than this period and the simulation can be extended to wash out that initialization bias.

% Burn-in for ensemble sampler
On the other hand, in an ensemble sampler, burn-in period might contain much larger biased samples relative to the total number of samples due to the use of multiple walkers within an iteration \cite{Hou2012,Foreman-Mackey2013,Akeret2013}.
Multiple walkers can be initialized from low probability region. 
Furthermore, the number of iterations in an ensemble sampler is relatively shorter than in a single particle sampler (and more expensive).
As such, determining the length of burn-in period and discarding the associated samples are considered more important for ensemble sampler.

% Burn-in and autocorrelation
Burn-in period can be associated with the relaxation period of an infinitely long Markov chain \cite{Sokal1997}.
In that case, the autocorrelation function of Eq.~(\ref{eq:ch5_autocorrelation}) asymptotically decays following exponential law, i.e., $\rho_f(t) \propto \exp{(-t/\tau_\text{exp,f})}$. 
Thus, the \emph{exponential} autocorrelation time of function $f$ then can be defined as follow,
\marginpar{Exponential autocorrelation time}
\begin{equation}
  \tau_{\text{exp},f} = \limsup\limits_{t\rightarrow\infty} \frac{t}{-\ln{|\rho_f(t)|}} 
\label{eq:ch5_markov_chain_exponential_autocorrelation_time}
\end{equation}
The \emph{exponential} autocorrelation time $\tau_\text{exp}$ of the \gls[hyper=false]{mcmc} simulation then taken to be the maximum autocorrelation time with respect to all functions $f$ of interest.
The time represents the rate of convergence of a Markov chain to its stationary distribution \cite{Sokal1997}.
It can be used to determine the number of iterations to discard before the chain can be considered stationary.

% Importance of Burn-in period revisited
The formal relationship exponential correlation time and stationarity holds only for strictly exponential correlation function which in turn valid for infinitely long chain \cite{Sokal1997}.
\marginpar{Determining the number of iterations to discard}
In practice, a conservative multiples of the exponential autocorrelation time $\tau_\text{exp}$, ranging from $5$ \cite{Foreman-Mackey2013} to $20$ \cite{Sokal1997}, is used to determine the total number of iterations to discard.
Generally, the exponential autocorrelation time is different from the integrated autocorrelation time except in the case of exponentially decaying autocorrelation function.
In practice, once more, they are often assumed to be the same \cite{Foreman-Mackey2013,Akeret2013} or at least having the same order of magnitude \cite{Sokal1997}.

In the end, it is important to acknowledge that burn-in period is a heuristic.
\marginpar{Burn-in, a heuristic}
It is useful to avoid initialization bias from a Markov chain of finite length especially in the case of ensemble samplers.
Moreover, a suspiciously long burn-in period can give an indication of a more serious underlying problem either in the posterior formulation or the sampler.
It cannot, however, establish the fact that a Markov chain has indeed settled in its stationary (and simultaneously, its target) distribution \cite{Sokal1997,Geyer2011}. 

% Why there's burn-in
The initial transient is mainly because an arbitrary value with low posterior probability is selected to initialize the chain.
\marginpar{Burn-in, alternatives}
In a simple problem, perhaps it is straightforward to determine a priori a value that lies on high probability region of the posterior.
This is not the case for a more complex high-dimensional problem and some arbitrary values are often selected instead.
Thus, some authors \cite{Geyer1992, Akeret2013} proposed instead to tune the initial values such that they are more representative to the posterior \gls[hyper=false]{pdf} and make do without burn-in.
This tuning, however, entails additional preliminary calculations.

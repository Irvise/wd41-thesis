%***********************************************
\subsection{Discussion}\label{sub:bc_discussion}
%***********************************************

%------------------------------------------------------------------------------------------------
\subsubsection{On the Convergence of the MCMC Simulation}\label{subsub:bc_discussion_convergence}
%------------------------------------------------------------------------------------------------

% Opening Paragraph, On Convergence
Though the length of burn-in period is almost $40\%$ of the total number of iterations -- thus discarding a lot of the initial samples -- the resulting statistical error associated with model parameters estimates is in the order of less than $1\%$ relative to the respective standard deviation.
The relatively long burn-in period with respect to the total number of ensemble iterations is consistent with the observations of Refs.~\cite{Hou2012,Foreman-Mackey2013,Akeret2013}, each of which applied an \gls[hyper=false]{aies} ensemble sampler to conduct a Bayesian calibration of a computer model.
This relatively long burn-in period is especially true in comparison with the length of the period in a single particle sampler.
It is not uncommon to run a single particle \gls[hyper=false]{mcmc} simulation up to $100'000$ iterations (or beyond) for computer model calibration \cite{Wu2017,Wu2018}.
In such case, the length of the burn-in period would be much smaller than the total number of iterations and thus would be less important to discard\footnote{A rule of thumb argues for discarding at most $20\%$ of the total number of samples in a single particle samplers \cite{Sokal1997}.}.

In the case considered here, although the total number of iterations are much smaller ($2'000$), the length of burn-in period was conservatively estimated up to $40\%$ of the total number of iterations\footnote{Note that, despite the lower number of iterations for an ensemble sampler, the computational cost of the sampler in terms of the number of likelihood evaluations is on par with a single particle sampler.}.
Therefore, determining the burn-in period was indeed more important;
if the samples associated with this initial transient were not discarded then the model parameters estimates would be heavily biased.

Finally, note that the only free parameter to deal with in this particular application of the ensemble sampler was the total number of iterations; no adjustment to the sampler itself during the iteration was required.

%------------------------------------------------------------------------------------------------------------------
\subsubsection{On the Constraining Ability of Data and Identifiability}\label{subsub:bc_discussion_identifiability}
%------------------------------------------------------------------------------------------------------------------

% On the Posterior samples, constraining power of data, and using different type of outputs
The resulting posterior samples, as presented in the corner plots (Figs.\ref{fig:ch5_plot_ens_all_disc_centered}, \ref{fig:ch5_plot_ens_tc_disc_centered}, \ref{fig:ch5_plot_ens_dp_disc_centered}, \ref{fig:ch5_plot_ens_co_disc_centered}, \ref{fig:ch5_plot_ens_all_disc_centered_noparam8}, and \ref{fig:ch5_plot_ens_all_nodisc}) and as summarized in Table~\ref{tab:ch5_post_param}, indicate different constraining ability of the data on the model parameters prior uncertainties depending on the calibration scheme.
\marginpar{On the posterior samples}
Figs.~\ref{fig:ch5_plot_ens_all_disc_centered}, \ref{fig:ch5_plot_ens_tc_disc_centered}, \ref{fig:ch5_plot_ens_dp_disc_centered}, and \ref{fig:ch5_plot_ens_co_disc_centered} demonstrates the constraining ability of different types of data.
These calibration results are to be expected according to the sensitivity analysis conducted in Chapter~\ref{ch:gsa}.
For instance, the pressure drop output mainly sensitive to the parameter \texttt{iafbIntDr} can be mainly informed by the pressure drop data as demonstrated in Fig.~\ref{fig:ch5_plot_ens_dp_disc_centered}.
Meanwhile, the liquid carryover output though sensitive to the variation of the model parameters \texttt{dffbVIHT} and \texttt{dffbIntDr} are overshadowed by the variation due to the boundary condition.
Thus, as indicated in Fig.~\ref{fig:ch5_plot_ens_co_disc_centered} the constraining power of the liquid carryover data is fairly limited; the posterior uncertainties associated with the important parameters remain wide.

% TC Output
The results are similar when considering only the clad temperature data for the calibration.
The parameters \texttt{gridHT} and \texttt{dffbWallHT} are well constrained by the temperature data.
The parameter \texttt{gridHT}, in particular, is constrained only at the upper end of the uncertainty bound.
It turns out that decreasing the spacer grid heat enhancement below certain value will not decrease the overall heat transfer any longer.
Thus, below that certain value the enhancement is insensitive with respect to the clad temperature output.

% All Outputs
By definition, a model parameter that is not sensitive to a simulation output cannot be informed by the experimental data of that output. 
That is, the parameter is non-identifiable \cite{Hines2014}.
\marginpar{Non-identifiability, multiple types of data}
And indeed, when considering all types of data, the prior uncertainties of the model parameters was shown to be simultaneously constrained and often even tighter (Fig.~\ref{fig:ch5_plot_ens_all_disc_centered}).
For instance, the parameter \texttt{iabfIntDr} is non-identifiable with respect to the temperature data while the parameter \texttt{dffWallHT} with respect to the pressure drop data.
Calibration using both experimental data solves the non-identifiability problem for both parameters.

% No Constrain
There are, however, several parameters that simply could not be constrained by the considered experimental data.
\marginpar{Non-identifiability, insensitive parameters}
The uncertainties, especially the lower bounds, of the parameters \texttt{iafbWHT}, \texttt{dffbWDr} and \texttt{tQuench} remained close its initial lower uncertainty bound,
while their upper bounds were only marginally smaller than that of the respective prior. 
These parameters were found to be of marginal importance relative among the selected influential parameters.
Although it is straightforward to conclude that insensitive parameter simply cannot be constrained by the experimental data, and the most influential ones can be strongly constrained, it stays unclear which among the parameters of intermediate importance as indicated by sensitivity measure of Chapter~\ref{ch:gsa} can be well constrained by the experimental data.

% On the Posterior samples, correlation structure On the Posterior samples, excluding dffbVIHTC
The calibration results also showed that strong correlation was pres\-ent among the model parameters.
\marginpar{Non-identifiability, correlation}
In the case of the calibration against $TC$ data (Fig.~\ref{fig:ch5_plot_ens_tc_disc_centered}), the parameter \texttt{dffbVIHT} was shown to be correlated with multiple parameters, particularly with the parameter \texttt{dffbIntDr}.
In the case of the calibration against $DP$ data (Fig.~\ref{fig:ch5_plot_ens_dp_disc_centered}), the parameters \texttt{iafbWHT} and \texttt{tQuench} were found to be strongly correlated. 
Considering multiple types of experimental data (Fig.~\ref{fig:ch5_plot_ens_all_disc_centered}) did not seem to break these correlations.
Both cases are examples of another form non-identifiability.
Though these parameters were sensitive with respect to the outputs as the parameters posterior uncertainties were clearly informed and affected by the calibration process (they did, after all, become correlated), 
the effect of one parameter could be be offset by the change in the other in reproducing the experimental data. 
As a result, the univariate posterior marginal uncertainties of these parameters remained large.

% On the Posterior samples, correlation structure On the Posterior samples, excluding dffbVIHTC
A possible, rather straightforward, solution of this problem is to remove an influential parameter that is strongly correlated from the calibration process \cite{Brun2002} and keeping them at its prior uncertainty.
\marginpar{Calibration, excluding a correlated parameter}
Indeed this approach was investigated by conducting the calibration scheme \texttt{w/ Bias, no dffbVIHT} in which the parameter \texttt{dffbVIHT} was excluded from the calibration process.
The results as presented in Fig.~\ref{fig:ch5_plot_ens_all_disc_centered_noparam8} which further constrained the uncertainty of the parameter \texttt{dffbIntDr} that was previously correlated with the excluded parameter.

% On the Posterior samples, no bias
The last calibration scheme investigated was the \texttt{w/o Bias} in which no model bias term was incorporated in the calibration process and the only source of uncertainties was the one associated with the reported experimental data.
\marginpar{Calibration, without model bias term}
The results as presented in Fig.~\ref{fig:ch5_plot_ens_all_nodisc} showed a peculiar behavior.
A notable feature was, for many model parameters, the nominal parameters values were found to be outside the respective $95\%$ posterior uncertainty range.
Recall that the nominal parameters were already calibrated against experimental data from different \glspl[hyper=false]{setf}.
Therefore, if this results is to be believed then it also implies that the previous calibration results are highly implausible.

Moreover, the posterior samples of the parameters were concentrated either in one corner of the prior uncertainty range or in either sides of it.
The parameters \texttt{iafbWHT} and \texttt{tQuench}, for instance, were concentrated in both sides of their prior uncertainties;
while the parameters \texttt{dffbWHT} and \texttt{dffbVIHT} were concentrated in one side of their prior uncertainties.
Though looked peculiar, the posterior samples were model parameters values that were found to be consistent with the experimental data under the calibration formulation.
The lack of assumed model bias in the calibration formulation did force the parameters to change dramatically and at times, to the limit of the prior uncertainties, in order to compensate any additional residual discrepancy between the simulator predictions and the experimental data, beyond the experimental uncertainty.

% On Uncertainty Propagation
To investigate the implication of the model parameters posterior uncertainties, obtained from different calibration schemes and on different \gls[hyper=false]{feba} tests, $1'000$ samples of model parameters values were taken from the respective pool of posterior samples and subsequently used in the model parameters uncertainties propagation (i.e., forward \gls[hyper=false]{uq}) through the \gls[hyper=false]{trace} model of \gls[hyper=false]{feba}.
The uncertainties of additional parameters related to boundary conditions were also propagated alongside the posterior uncertainties of the model parameters.
For comparison purpose, uncertainty propagation was also conducted in which the correlation among model parameters was neglected (i.e., the model parameters were taken to be independent of each other).
In the following, the discussion is focused on the propagation of posterior uncertainties obtained from three calibration schemes, namely: \texttt{w/ Bias, All}, \texttt{w/o Bias}, and \texttt{w/ Bias, no dffbVIHT}.

% On Uncertainty Propagation, Calibration vs. Informativeness
The notions of informativeness and calibration score were used to summarize the resulting prediction uncertainties associated with different posterior samples on different \gls[hyper=false]{feba} tests.
\marginpar{On the model parameters posterior uncertainties propagation}
The usage of these two notions in this thesis were mainly for comparison purpose: an increase in informativeness implied a narrower prediction uncertainty band and vice versa;
while an increase in calibration score implied a smaller discrepancy between a prediction and its observed data.
By construction, the calibration score put a high penalty for a failure of an uncertainty band to cover experimental data; it assigned the value of zero.

As it was shown in Fig.~\ref{fig:ch5_plot_calib_info}, all the calibration schemes managed to improve the informativeness of the prediction while simultaneously decreased the calibration score.
\marginpar{Informativeness vs. calibration score of the posterior prediction uncertainties}
The tightening of the uncertainty band caused failure in covering some of the experimental data points.
These points, a portion of the overall reflood transient, often looked very different from the typical \gls[hyper=false]{trace} prediction.
Consequently, the prediction could not be altered (by altering the model parameters) to cover that portion of the transient without increasing the discrepancy with the experimental data in other part of the transient.
As such, though the resulting posterior uncertainties resulted in lower calibration scores than the prior, they also resulted in uncertain predictions that have overall smaller discrepancy with the experimental data.

The calibration without considering model bias term often gave the most informative prediction of them all.
\marginpar{Calibration without model bias term, overfitting}
On the other hand, it also gave the lowest calibration scores across tests for the $TC$ and $DP$ outputs.
This indicated a strong overfitting.
It did, however, give a significant improvement on the prediction of the liquid carryover ($CO$) both in terms of informativeness and calibration score across tests.
As the nominal \gls[hyper=false]{trace} prediction for the liquid carryover showed a large discrepancy with the experimental data, this improvement implied that the uncertain predictions had been altered significantly from the nominal prediction.

It was also observed that neglecting correlation between parameters had a profound impact on the calibration score and informativeness: it inflated the prediction uncertainty while simultaneously improve the calibration score.
\marginpar{Correlated parameters, impact}
The effect of neglecting the correlation on the informativeness and calibration score was particularly striking for the results from the calibration scheme \texttt{w/ Bias, All}.
This implies that correlation among model parameters is a form of information in the model parameters uncertainties that is specific to the calibration data used.
It can be argued that in the case of the calibration scheme \texttt{w/ Bias, All}, even with the inclusion of model bias term in the calibration, some parameters in the resulting posterior becomes highly correlated such that it is overfitted to the calibration data.
It gives prediction with high informativeness while decreasing the calibration score.
At the same time, for similar informativeness across tests, the prediction using the posterior uncertainties of the calibration scheme \texttt{w/ Bias, All} yield higher calibration score (except for the $CO$ output explained above).
That is, it is still less overfitted as compared to the calibration without the model bias term.

Finally, removing the most influential correlated parameter (\texttt{dffbVIHT}) from the calibration and keeping its uncertainties at the prior range gave good compromise.
The resulting prediction uncertainties showed a decent increase in the informativeness and a minor decrease in the calibration score across all tests.

% On Uncertainty Propagation, TC1 FEBA Test 216 Different Calibration Schemes
By looking at the plots similar to Figs.~\ref{fig:ch5_plot_trace_uq_post_all_disc_tc_216}, \ref{fig:ch5_plot_trace_uq_post_all_disc_dp_216}, and \ref{fig:ch5_plot_trace_uq_post_all_disc_co_216} available in the Appendix~\ref{app:mcmc_evaluation}, the difference between the uncertainty propagation of the posterior uncertainties from the three calibration schemes can mainly be observed on two outputs $TC1$ (the clad temperature at the top of the assembly) and $CO$.
Fig.~\ref{fig:ch5_plot_feba_216_tc1_post} shows the uncertainty propagation results for the $TC1$ output.
The uncertainty band from the calibration scheme \texttt{w/ Bias, All} (and to a lesser extend the one from the scheme \texttt{w/ Bias, no dffbVIHT}) shows a consistent shape with the nominal \gls[hyper=false]{trace} prediction.
The band from the scheme \texttt{w/o Bias} is dramatically different (Fig.~\ref{fig:ch5_plot_feba_216_tc1_post_2}); it bears no resemblance whatsoever with the nominal \gls[hyper=false]{trace} prediction.
Moreover, the nominal \gls[hyper=false]{trace} prediction falls completely outside the uncertainty band.
As the predictions from the other axial elevations showed no such dramatic difference, and by comparing with the results of the scheme \texttt{w/ Bias, no dffbVIHT}, it can be inferred that the parameter \texttt{dffbVIHT} is the one mainly responsible for this difference.
\bigtriplefigure[pos=tbhp,
                 mainlabel={fig:ch5_plot_feba_216_tc1_post},
			           maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of \gls[hyper=false]{feba} test No. $216$ with the posterior of the model parameters from $3$ different calibration schemes. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA test No. $216$ with the posterior of the model parameters from $3$ different calibration schemes.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_216_tc1_post_1},
			           leftcaption={\texttt{w/ Bias, All}},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_216_tc1_post_2},
			           midcaption={\texttt{w/o Bias}},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_216_tc1_post_3},
			           rightcaption={\texttt{w/ Bias, no dffbVIHT}},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA216TC1Post_1}
{../figures/chapter5/figures/plotFEBA216TC1Post_2}
{../figures/chapter5/figures/plotFEBA216TC1Post_3}

% Source of correlation
Fig.~\ref{fig:ch5_plot_feba_216_tc1_post} also illustrates that the posterior samples from the calibration scheme \texttt{w/ Bias, All} are indeed strongly correlated, ignoring the correlation changes significantly the resulting uncertainty bands of the prediction.
In other words, the model parameters only takes specific range of values in concert to reproduce the data.
In this illustration, the correlation among parameters tighten the uncertainty band while keeping the experimental data within it.
Moreover, as it was suspected, the parameter \texttt{dffbVIHT} is responsible for the strong correlation;
ignoring the correlation structure in the uncertainty propagation of the results from the scheme  \texttt{w/ Bias, no dffbVIHT} shows a marginal difference compared to the propagation with the correlation structure. 

%-------------------------------------------------------------------------------------------------------
\subsubsection{On the Calibration with and without the Model Bias Term}\label{subsub:bc_discussion_bias}
%-------------------------------------------------------------------------------------------------------

% CO FEBA Test 216 Different Calibration Schemes
At the same time, allowing the parameter \texttt{dffbVIHT} to change dramatically from the initial nominal parameter value also allowed the calibration scheme \texttt{w/o Bias} to correct the bias in the prediction of liquid carryover as indicated in Fig.~\ref{fig:ch5_plot_feba_216_co_post_2}.
Now the nominal \gls[hyper=false]{trace} prediction mostly falls outside the posterior uncertainty band.
By construction, the other two schemes allowed the nominal \gls[hyper=false]{trace} prediction to be within their respective posterior uncertainty bands although the bands did not (or only marginally) cover the experimental data.
As the calibration was conducted with respect to all other outputs of which many more data points were available this simply means that the agreement with respect to the other outputs offset the discrepancy of the liquid carryover. 
\bigtriplefigure[pos=tbhp,
                 mainlabel={fig:ch5_plot_feba_216_co_post},
			           maincaption={Uncertainty propagation results for $CO$ output of \gls[hyper=false]{feba} test No. $216$ with the posterior of the model parameters from $3$ different calibration schemes. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $CO$ output (the clad temperature at the top of the assembly) of FEBA test No. $216$ with the posterior of the model parameters from $3$ different calibration schemes.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_216_co_post_1},
			           leftcaption={\texttt{w/ Bias, All}},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_216_co_post_2},
			           midcaption={\texttt{w/o Bias}},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_216_co_post_3},
			           rightcaption={\texttt{w/ Bias, no dffbVIHT}},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA216COPost_1}
{../figures/chapter5/figures/plotFEBA216COPost_2}
{../figures/chapter5/figures/plotFEBA216COPost_3}

% Connection with sensitivity analysis
This is supported by the sensitivity analysis conducted in the previous chapter where it was shown that the parameter \texttt{dffbVIHT} became increasingly important at the top of the assembly and it was also found to be important for the $CO$ output.
Recall that the parameter \texttt{dffbVIHT} is responsible for the heat transfer between the vapor phase and the interface and it contributes to the variation in the available entrained liquid and droplets being carried away through the top of the assembly.
These droplets, in turn, is an important heat sink for the cladding.
Thus, an increase in the heat transfer coefficient enhances the heat transfer at the top of the assembly and accelerate the evaporation of the available droplets (thus the lower clad temperature) while simultaneously decreases the amount of liquid being carried away (thus the slower rate of liquid carryover collection).

%---------------------------------------------------------------------------------------------------
\subsubsection{On the Effect of Boundary Conditions}\label{subsub:bc_discussion_boundary_conditions}
%---------------------------------------------------------------------------------------------------

% TC1 All FEBA Tests Calibration with model bias, kinda look better
When comparing the uncertainty propagation results of the output $TC1$ across \gls[hyper=false]{feba} tests, another peculiar finding can be observed.
Fig.~\ref{fig:ch5_plot_feba_tc1_disc_better} shows the uncertainty propagation with respect to the output $TC1$ for \gls[hyper=false]{feba} test Nos. $216$, $220$, and $222$ using the model parameters posterior uncertainties from the calibration scheme \texttt{w/ Bias, All}.
It is obvious for the test No. $216$, the calibration data, to be well predicted and covered by the posterior model parameters uncertainties (Fig~\ref{fig:ch5_plot_feba_tc1_disc_216}).
The prediction for the test No. $220$ (Fig~\ref{fig:ch5_plot_feba_tc1_disc_220}) looks even better.
While the experimental data for the test No. $222$ falls outside the uncertainty band (of the correlated posterior samples), the shape of the experimental data looks very similar to typical uncertain predictions as represented by the band.
\bigtriplefigure[pos=tbhp,
                 mainlabel={fig:ch5_plot_feba_tc1_disc_better},
			           maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, All}. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, All}.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_tc1_disc_216},
			           leftcaption={Test No. $216$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_tc1_disc_220},
			           midcaption={Test No. $220$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 3.9\,[cm \cdot s^{-1}]$},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_tc1_disc_222},
			           rightcaption={Test No. $222$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA216TC1PostDisc}
{../figures/chapter5/figures/plotFEBA220TC1PostDisc}
{../figures/chapter5/figures/plotFEBA222TC1PostDisc}

% TC1 All FEBA Tests Calibration without model bias, kinda look bad
On the contrary, the uncertainty propagation with respect to the output $TC1$ for \gls[hyper=false]{feba} test Nos. $216$, $220$, and $222$ using the model parameters posterior uncertainties from the calibration scheme \texttt{w/o Bias} look significantly off compared with both the experimental data and the nominal \gls[hyper=false]{trace} prediction (Fig.~\ref{fig:ch5_plot_feba_tc1_nodisc_worse}).
\bigtriplefigure[pos=tbhp,
                 mainlabel={fig:ch5_plot_feba_tc1_nodisc_worse},
			           maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/o Bias}. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/o Bias}.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_tc1_nodisc_216},
			           leftcaption={Test No. $216$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_tc1_nodisc_220},
			           midcaption={Test No. $220$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 3.9\,[cm \cdot s^{-1}]$},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_tc1_nodisc_222},
			           rightcaption={Test No. $222$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA216TC1PostNoDisc}
{../figures/chapter5/figures/plotFEBA220TC1PostNoDisc}
{../figures/chapter5/figures/plotFEBA222TC1PostNoDisc}

% TC1 All FEBA Tests Calibration with model bias, kinda look worse
In the case of the uncertainty propagation with respect to the output $TC1$ for \gls[hyper=false]{feba} test Nos. $214$, $218$, and $223$, it is the the model parameters posterior uncertainties from the calibration scheme \texttt{w/ Bias, All} that produces significantly different results compared with the experimental data (Fig~\ref{fig:ch5_plot_feba_tc1_disc_worse}).
The experimental data of test Nos. $218$ and $223$, in particular, are very much different than a typical \gls[hyper=false]{trace} predictions, both the nominal prediction and the corresponding uncertainty band.
Neglecting the correlation structure between the model parameters inflates the uncertainty band and increase the coverage of the experimental data but the experimental data still looks dissimilar.
This gives an indication that the observed phenomena might be of different nature, or there is a missing physical process in the simulation of reflood test with a lower system pressure.
In the case of a very strong bias, under the calibration scheme, the adjustment of the model parameters is not enough to allow \gls[hyper=false]{trace} to better reproduce experimental data. 
\bigtriplefigure[pos=tbhp,
                 mainlabel={fig:ch5_plot_feba_tc1_disc_worse},
			           maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, All}. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, All}.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_tc1_disc_214},
			           leftcaption={Test No. $214$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_tc1_disc_218},
			           midcaption={Test No. $218$, $P_\text{sys} = 2.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_tc1_disc_223},
			           rightcaption={Test No. $223$, $P_\text{sys} = 2.2\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA214TC1PostDisc}
{../figures/chapter5/figures/plotFEBA218TC1PostDisc}
{../figures/chapter5/figures/plotFEBA223TC1PostDisc}

% TC1 All FEBA Tests Calibration without model bias, kinda look better
And yet, the uncertainty propagation with respect to the output $TC1$ using the model parameters posterior uncertainties from the calibration scheme \texttt{w/o Bias} do not look terribly look off for \gls[hyper=false]{feba} test Nos. $214$, $218$, and $223$.
While the resulting uncertainty bands still fail to cover most of the experimental data, the upper uncertainty bounds of each test look conspicuously similar to the experimental data.
As mentioned the experimental data of $TC1$ for these three tests do not exhibit a typical reflood curve.
At the same time, there is a potential for \gls[hyper=false]{trace} to properly reproduce the data through a significant adjustment to the nominal values of some parameters (e.g., \texttt{dffbVIHT}) as it was allowed by the calibration scheme \texttt{w/o Bias}.
\bigtriplefigure[pos=tpbhp,
                 mainlabel={fig:ch5_plot_feba_tc1_nodisc_better},
			           maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/o Bias}. The uncertainty bands from darkest to lightest color correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/o Bias}.},%
			           leftopt={width=0.31\textwidth},
			           leftlabel={fig:ch5_plot_feba_tc1_nodisc_214},
			           leftcaption={Test No. $214$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           midopt={width=0.31\textwidth},
			           midlabel={fig:ch5_plot_feba_tc1_nodisc_218},
			           midcaption={Test No. $218$, $P_\text{sys} = 2.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           rightopt={width=0.31\textwidth},
			           rightlabel={fig:ch5_plot_feba_tc1_nodisc_223},
			           rightcaption={Test No. $223$, $P_\text{sys} = 2.2\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           spacing={},
			           spacingtwo={}]
{../figures/chapter5/figures/plotFEBA214TC1PostNoDisc}
{../figures/chapter5/figures/plotFEBA218TC1PostNoDisc}
{../figures/chapter5/figures/plotFEBA223TC1PostNoDisc}

Therefore, it is worth investigating in a further study whether a proper parametrization with respect to system pressure and reflood rate have been implemented in \gls[hyper=false]{trace}.
Based on this study and for this particular output (the clad temperature at the top of the assembly), it is perhaps the case that a different reflood closure models adjustment are required for properly simulating reflood in a low system pressure or in an intermediate system pressure but with higher reflood rate particularly in the upper part of the assembly.

%Meanwhile, it might well be the case that the phenomena being measured for the \gls[hyper=false]{feba} test Nos. $214$, $218$, and $223$ are simply not representative to what being simulated by \gls[hyper=false]{trace} according to its verification and validation activities.

%% TC1 All FEBA Tests Calibration with model bias but no param 8, look so so 
%\bigtriplefigure[pos=tbhp,
                 %mainlabel={fig:ch5_plot_feba_tc1_noparam8_1},
			           %maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration schemes \texttt{w/ Bias, no dffbVIHT}. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           %mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $216$, $220$, and $222$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, no dffbVIHTC}.},%
			           %leftopt={width=0.31\textwidth},
			           %leftlabel={fig:ch5_plot_feba_tc1_noparam8_216},
			           %leftcaption={Test No. $216$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           %midopt={width=0.31\textwidth},
			           %midlabel={fig:ch5_plot_feba_tc1_noparam8_220},
			           %midcaption={Test No. $220$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 3.9\,[cm \cdot s^{-1}]$},
			           %rightopt={width=0.31\textwidth},
			           %rightlabel={fig:ch5_plot_feba_tc1_noparam8_222},
			           %rightcaption={Test No. $222$, $P_\text{sys} = 6.2\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           %spacing={},
			           %spacingtwo={}]
%{../figures/chapter5/figures/plotFEBA216TC1PostDiscNoParam8}
%{../figures/chapter5/figures/plotFEBA220TC1PostDiscNoParam8}
%{../figures/chapter5/figures/plotFEBA222TC1PostDiscNoParam8}
%
%% TC1 All FEBA Tests Calibration with model bias but no param 8, look so so
%\bigtriplefigure[pos=tbhp,
                 %mainlabel={fig:ch5_plot_feba_tc1_noparam8_2},
			           %maincaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, no dffbVIHT}. The uncertainty bands from darkest to lightest shades correspond to the prior, posterior (independent), and posterior (correlated) model parameters uncertainties, respectively.},
			           %mainshortcaption={Uncertainty propagation results for $TC1$ output (the clad temperature at the top of the assembly) of FEBA tests No. $214$, $218$, and $223$ with the posterior uncertainties of the model parameters from the calibration scheme \texttt{w/ Bias, no dffbVIHTC}.},%
			           %leftopt={width=0.31\textwidth},
			           %leftlabel={fig:ch5_plot_feba_tc1_noparam8_214},
			           %leftcaption={Test No. $214$, $P_\text{sys} = 4.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           %midopt={width=0.31\textwidth},
			           %midlabel={fig:ch5_plot_feba_tc1_noparam8_218},
			           %midcaption={Test No. $218$, $P_\text{sys} = 2.1\,[bar]$, $V_\text{in} = 5.8\,[cm \cdot s^{-1}]$},
			           %rightopt={width=0.31\textwidth},
			           %rightlabel={fig:ch5_plot_feba_tc1_noparam8_223},
			           %rightcaption={Test No. $223$, $P_\text{sys} = 2.2\,[bar]$, $V_\text{in} = 3.8\,[cm \cdot s^{-1}]$},
			           %spacing={},
			           %spacingtwo={}]
%{../figures/chapter5/figures/plotFEBA214TC1PostDiscNoParam8}
%{../figures/chapter5/figures/plotFEBA218TC1PostDiscNoParam8}
%{../figures/chapter5/figures/plotFEBA223TC1PostDiscNoParam8}

% Nominal Value revisited

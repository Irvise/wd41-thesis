%******************************************************************************************************************************
\section[Diagnosing Convergence]{Diagnosing Convergence of an \gls[hyper=false]{mcmc} Simulation}\label{sec:bc_mcmc_diagnostic}
%******************************************************************************************************************************

% With a minimal tuning to deal with in AIES algorithm, we are left with the problem of assessing convergence.
% In particular two key issues persists
% The previous discussion spoke rarely about the condition.
% It was demonstrated, through graphical representations the main idea of convergence in distributin.
% This section seeks to answer, the following two important questions of Markov chain 
% For an arbitrary starting distribution, when the chain can be considered stationary
% It is not to say that these initial part of the chain is not part of the target distribution support.
% They are, but as a distribution they are heavily biased.
% Assuming a stationary distribution have been reached, how long the chain should be run to meet certain level of accuracy

% Opening paragraph
Consider once more Eq.~(\ref{eq:ch5_markov_chain_clt}), the central limit theorem (CLT) for the \gls[hyper=false]{mcmc} and repeated below,
\begin{equation*}
  \lim_{I \rightarrow \infty} \,\, \frac{1}{I} \sum_{i=1}^I f(\bm{x}^{(i)}) - \mathbb{E}_{\pi^*}[f] \thicksim \mathcal{N} \left(0, \frac{\sigma_f^2}{I}\right)
\end{equation*}
Where $\sigma^2_f$ is the variance of a given function $f$ evaluated under the stationary density of the chain.
As mentioned, by construction the successive realizations in a Markov chain is not independent because successive iterations are correlated.
Therefore, the term $\sigma^2_f$ is now given by \cite{Geyer2011},
\begin{equation*}
  \sigma_f^2 = \mathbb{V} + \text{Cov}
\label{eq:ch5_markov_chain_variance}
\end{equation*}

%-----------------------------------------------------------------------------------------------------------------
\subsection[Autocovariance and Autocorrelation of MCMC samples]{Autocovariance and Autocorrelation of MCMC samples}\label{sub:bc_mcmc_diagnostic_autocovariance}
%-----------------------------------------------------------------------------------------------------------------

The autocorrelation function $\rho_f$ of $f$ is defined as
\begin{equation}
  \rho_f (t) \equiv \frac{C_f(t)}{C_f(0)}
\label{eq:ch5_autocorrelation}
\end{equation}
where $C_f(0)$ is the lag-$0$ autocovariance and is equal to the process variance $\mathbb{V}[f]$ for a stationary process.

%-----------------------------------------------------------------------------------------------------------------
\subsection[Autocorrelation in Equilibrium]{Autocorrelation in Equilibrium}\label{sub:bc_mcmc_diagnostic_thinning}
%-----------------------------------------------------------------------------------------------------------------

Assuming that the stationary chain has been attained the asymptotic results of Eq.~(\ref{eq:ch5_markov_chain_clt}) applies.
To derive the expression for $\sigma^2_f$ in the equation, consider that the variance of the \gls[hyper=false]{mcmc} estimator $\hat{f}$ for the expected value of $f$ computed by a Markov chain $\{\bm{\mathcal{X}}^{(i)}\}$ of length $I$ is given by,
\begin{equation}
  \mathbb{V}[\,\hat{f}\,] = \mathbb{E}\left[\left(\frac{1}{I} \sum_{i=1}^I \left( f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right)\right)^2 \right]
\label{eq:ch5_markov_chain_estimate_variance}
\end{equation}
by using nested sum, the definition can be rewritten as,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & = \mathbb{E}\left[\frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \left(f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right) \cdot \left(f[\bm{\mathcal{X}}^{(j)}]  - \mathbb{E}[f] \right) \right] \\
  & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \mathbb{E}\left[\left(f[\bm{\mathcal{X}}^{(i)}]  - \mathbb{E}[f] \right) \cdot \left(f[\bm{\mathcal{X}}^{(j)}]  - \mathbb{E}[f] \right) \right] \\
  & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \text{Cov} \left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(j)}) \right]
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_nested_sum}
\end{equation*}

Assuming that the chain $\{\bm{\mathcal{X}}^{(i)}\}$ is stationary then the covariance function is simply a function of the separation between the two iterations $i$ and $j$,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & =  \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I \text{Cov} \left[ f(\bm{\mathcal{X}}^{(i)}), f(\bm{\mathcal{X}}^{(j)}) \right] \\
                          & = \frac{1}{I^2} \sum_{i=1}^I \sum_{j=1}^I C_f (|i - j|) \\
                          & \approx \frac{1}{I^2} \sum_{i=1}^I \sum_{t = -\infty}^{\infty} C_f (|t|) = \frac{1}{I} \sum_{t = -\infty}^{\infty} C_f (|t|)
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_stationary}
\end{equation*}
where $C_f$ is the (stationary) autocovariance function associated with function $f$.
The approximation in the last line above is valid assuming that $C_f$ decays as the separation $t = i - j$ becomes larger \cite{Sokal1997}.
Noting that the covariance function $C_f$ is a symmetric function about zero,
\begin{equation*}
  \begin{split}
  \mathbb{V}[\,\hat{f}\,] & = \frac{1}{I} \left( C_f (0) + 2 \sum_{t = 1}^{\infty} C_f (t) \right) \\
                          & = \frac{2 C_f (0)}{I} \left( \frac{1}{2} + \sum_{t = 1}^{\infty} \rho_f (t) \right)
  \end{split}
\label{eq:ch5_markov_chain_estimate_variance_expand}
\end{equation*}
where $\rho_f$ is the autocorrelation function of $f$ defined in Eq.~(\ref{eq:ch5_autocorrelation}).
Rearranging the term, the variance of the \gls[hyper=false]{mcmc} estimator $\hat{f}$ is given by,
\begin{equation}
  \mathbb{V}[\,\hat{f}\,] = \frac{2 \tau_{\text{int},f}}{I} C_f (0) 
\label{eq:ch5_markov_chain_estimator_variance}
\end{equation}
\marginpar{Integrated autocorrelation time}
where $\tau_{\text{int},f}$, the \emph{integrated autocorrelation time} (or simply autocorrelation time), is defined as,
\begin{equation}
  \tau_{\text{int},f} =  \left( \frac{1}{2} + \sum_{t = 1}^{\infty} \rho_f (t) \right)
\label{eq:ch5_markov_chain_autocorrelation_time}
\end{equation}

In making connection with Eq.~(\ref{eq:ch5_markov_chain_clt}), Eq.~(\ref{eq:ch5_markov_chain_estimator_variance}) can be interpreted in two ways.
\marginpar{Effective sample size}
First, the use of Markov chain of length $I$ to estimate the integral of $f$ inflates the true variance of $f$ (i.e., $C_f(0)$) by factor $2 \tau_{\text{int},f}$ in the computation of the \gls[hyper=false]{mc} sampling variance.
In other words, $\sigma^2_f \equiv 2 \tau_{\text{int},f} C_f(0)$.
Or, equivalently, the number of independent samples required in the computation of the \gls[hyper=false]{mc} sampling variance is only a factor of $\frac{1}{2 \tau_{\text{int},f}}$ of the total \gls[hyper=false]{mcmc} samples $I$.
In other words, $N \equiv \frac{I}{2 \tau_{\text{int},f}}$ with $N$ the number of independent samples (or \emph{effective sample size}).

% Autocorrelation time and the length of the chain
In either interpretation, the statistical error associated with the \gls[hyper=false]{mc} estimation is larger for an estimation using \gls[hyper=false]{mcmc} samples than using independent samples due to the inherent correlation.
\marginpar{Determining length of a chain}
Moreover, in the case of \gls[hyper=false]{mcmc}, the autocorrelation time $\tau_{\text{int},f}$ directly affects the statistical error.
As such, this quantity is useful in either determining the required length of the chain in a \gls[hyper=false]{mcmc} simulation or assessing the statistical error for chain of a given length.
That is the (required) relative statistical error of the estimator $\epsilon$ is related to the length of the chain through \cite{Akeret2013},
\begin{equation}
  \left(\frac{\mathbb{V}[\hat{f}]}{C_f(0)}\right)^{0.5} = \left(\frac{\mathbb{V}[\hat{f}]}{\mathbb{V}[f]}\right)^{0.5} = \left(\frac{2\tau_{\text{int},f}}{I}\right)^2 \leq \epsilon \Leftrightarrow I \geq \frac{2\tau_{\text{int},f}}{\epsilon^2} 
\label{eq:ch5_markov_chain_relative_error}
\end{equation}
where $I$ is the number of iterations \emph{and} samples for a single particle \gls[hyper=false]{mcmc}.
For an ensemble sampler the number of iterations should be multiplied by the number of walkers $L$ such that the condition above,
\begin{equation}
  I \geq \frac{2\,\tau_{\text{int},f}}{\epsilon^2\,L} 
\label{eq:ch5_markov_chain_relative_error_ensemble}
\end{equation}
%Note that the autocorrelation time is associated with a given function $f$ and have to be computed for different choice of $f$.

% On thinning
The notion of independent samples (or effective sample size) mentioned above are coupled with the practice of \emph{thinning} or sub-sampling the \gls[hyper=false]{mcmc} samples \cite{Geyer1992}.
\marginpar{On thinning the chain}
Thinning the chain means that only $1$ \gls[hyper=false]{mcmc} sample is kept for every $k$ iteration, with $k$ an integer.
Historically, thinning is also motivated by the limited storage and memory to store all the samples, especially for a long running \gls[hyper=false]{mcmc} simulation.
As such, it was argued that by thinning only, samples of that matters (i.e., independent) are kept for further analysis.

On the other hand, the practice of thinning is questioned by several authors \cite{Geyer1992,Link2011}.
The argument against thinning is relatively easy to intuit.
By conducting thinning the autocorrelation in the sample can be reduced thus reducing the statistical error of the estimate.
At the same time, there would be much smaller number of samples after thinning that often off-set the reduction of the error by a smaller autocorrelation time.
 
Thinning can be justified especially in the case expensive ``post-processing'' of the \gls[hyper=false]{mcmc} samples.
In other words, if the function $f$ is expensive to evaluate.
For example, in the context of Bayesian data analysis, the posterior samples obtained via \gls[hyper=false]{mcmc} simulation might need to be propagated through a computationally expensive code for the purpose of forward uncertainty quantification by an ordinary \gls[hyper=false]{mc} simulation.
In this case, only calculations of a few samples might be afforded and, as required by \gls[hyper=false]{mc} simulation, such selection of samples should be independent of each other which, in turn, can be achieved by thinning the chain first. 

%-----------------------------------------------------------------------------------------------------------------
\subsection[Initialization Bias and burn-in]{Initialization bias and burn-in}\label{sub:bc_mcmc_diagnostic_burnin}
%-----------------------------------------------------------------------------------------------------------------

The results above holds for \gls[hyper=false]{mcmc} samples obtained from a stationary chain.

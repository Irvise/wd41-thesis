%******************************************************************
\section{Statistical Framework}\label{sec:bc_statistical_framework}
%******************************************************************

% Introductory Paragraph
The calibration framework in this thesis is in line with the seminal work of Kennedy and O'Hagan \cite{Kennedy2001} which is widely adapted in the applied literature \cite{Bayarri2007,Higdon2008,Arendt2012,Reichert2012}.
\marginpar{Calibration framework}
Meanwhile its explicit formulation uses a notation adapted from different sources \cite{Kennedy2001,Santner2003,Reichert2012}.
Let $y_E$ be the experimental observation of a variable,
then its relationship to the true value $y_T$ is given by
\begin{equation}
    y_E(\bm{x}_c; \lambda) = y_T (\bm{x}_c; \lambda) + \epsilon
\label{eq:bc_observation_true}
\end{equation}
where $\epsilon$ is an observation error.
The true value, in turn, is linked to the prediction made by a computer simulator of a physical model $y_M$,
\begin{equation}
    y_T(\bm{x}_c; \lambda) = y_M (\bm{x}_c, \hat{\bm{x}}_m; \lambda) + \delta (\bm{x}_c; \lambda)
\label{eq:bc_true_simulation}
\end{equation}
That is, apart from the \emph{model bias} $\delta$, the simulator prediction is potentially a valid representation of the true value.
Finally, combining the two relationships yields,
\begin{equation}
    y_E(\bm{x}_c; \lambda) = y_M (\bm{x}_c, \hat{\bm{x}}_m; \lambda) + \delta (\bm{x}_c; \lambda) + \epsilon
\label{eq:bc_observation_true}
\end{equation}
These representations are parametrized by \emph{controllable} parameters $\bm{x}_c$,
the best values of \emph{model} parameters $\hat{\bm{x}}_m$, and an element of an \emph{observation layout} $\lambda$.

% Parameterization, Model parameters vs Control variables
Departing from the previous chapters, this chapter categorically distinguishes two types of input parameters: a controllable input parameter $x_c$ and a model input parameter $x_m$.
\marginpar{Controllable inputs}
A controllable input parameter (also known as design variable) is an input that, in the context of controlled experiment, can be controlled by the experimenter.
Its value is often varied in the physical experiment either to investigate the system behavior under the change or to find the setting that gives the best system performance. 
Being controllable implies that the input can be observed and it has an equivalence in the actual physical experiment.
An example of such input is the parameters related to boundary conditions of an experiment.

The model input parameters, on the other hand, refer to parameters that are observable and often only exist in the parametrization of the model inside the simulator.

% Observation layout
An observation layout $\boldsymbol{\Lambda}$ is an index set and it defines which of the different types of variable being observed (or predicted) as well as their locations and instances.
\marginpar{Observation layout}
In this manner, long vectors for model prediction and experimental data can be constructed \cite{Reichert2012}.
For instance, the observation layout $\boldsymbol{\Lambda} = \{(A,t_1), (B,t_1), (A, t_2)\}$ might be used to signify model output/experimental data of variable $A$ at time $t_1$, variable $B$ at time $t_1$, and variable $A$ at time $t_2$.
The vectors $\bm{y}_M(\circ;\lambda)$ and $\bm{y}_E(\circ;\lambda)$ for $\lambda \in \boldsymbol{\Lambda}$ then refer to the model prediction and experimental data given by the index set, respectively.

% Goal of Calibration
The goal of calibration, in classical sense (citation needed), is to obtain the best value of $\bm{x}_c$ base on the available experimental data $y$.
This is done through an optimization procedure with respect to some error measures between predicted value and experimental data, such that the difference is consistent with the measurement error.

% Statistical Calibration of Kennedy and O'Hagan

% Model calibration, definition and its classical sense
Model calibration refers to the process of inferring model parameters values based on the difference between observed/measured data and model output (8).
\marginpar{Model calibration}
Inference implies that the parameter values are not necessarily observable as in the case of reflood model parameters presented in this study.
Calibration, in traditional sense, then proceed to identify a set of model parameters values that best fits the available data (9).


% Complication in model calibration

% Statistical Calibration

% Statistical Calibration of KOH

% Bayes' theorem revisited

% Citation 8: van Oijen
% Citation 9: Campbell
% KOH Approach, the chapter's notational convention
\begin{equation}
    y^T(\bm{x}_c) = y^M (\bm{x}_c, \bm{\hat{x}}_m) + \delta(\bm{x}_c)
\label{eq:bc_koh_true_model}
\end{equation}

% KOH Approach, the chapter's notational convention
\begin{equation}
    y^{Exp.}(\bm{x}_c) = y^T (\bm{x}_c) + \epsilon
\label{eq:bc_koh_true_measured}
\end{equation}

% Control and Model Parameters
% Simulator and Model discrepancy

% The meaning of true parameters

% The essence of Bayesian Data Analysis:
% 1. Set up full probabilistic model
% 2. Carry out Bayesian Computation
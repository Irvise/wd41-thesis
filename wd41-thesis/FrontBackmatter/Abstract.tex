%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

% Context and Need
Nuclear \gls[hyper=false]{th} system codes use several parame\-trized physical or empirical models to describe complex two-phase flow phenomena.
The reliability of their predictions is as such primarily affected by the uncertainty associated with the parameters of the models.
Because these model parameters often cannot be measured, nor have inherent physical meanings, their uncertainties are mostly based on expert judgment. 

% Goal
The present doctoral research aims to quantify the uncertainty of physical model parameters implemented in a \gls[hyper=false]{th} system code based on experimental data.
Specifically, this thesis develops a methodology to use experimental data to inform these uncertainties in a more objective manner.
The methodology is based on a probabilistic framework and consists of three steps adapted from recent developments in applied statistics: \gls[hyper=false]{gsa}, metamodeling, and Bayesian calibration.
The methodology is applied to reflood experiments from the \gls[hyper=false]{feba} test facility, which are modeled with the \gls[hyper=false]{th} system code \glsentryshort{trace}.
Reflood is chosen as a relevant phenomenon for the safety analysis of light water reactors (LWRs) and three typical time-dependent outputs are investigated: cladding temperature, pressure drops and liquid carryover.

In the first step, GSA allows screening out input parameters that have a low impact on the reflood transient.
\gls[hyper=false]{fda} is then used to reduce the dimensionality of the time-dependent code outputs, while preserving their interpretability.
The resulting quantities can be used once more with \gls[hyper=false]{th} to investigate, quantitatively, the effect of the input parameters on the overall time-dependent outputs.

In the second step, a \gls[hyper=false]{gp} metamodel is developed and validated as a surrogate for the TRACE model.
The average prediction error of the metamodel is sufficient to predict all considered outputs, and its computational cost is less than $5\,[s]$ as compared to $6-15\,[min]$ per \glsentryshort{trace} run. 

In the final step, the a posteriori model parameter uncertainties are quantified based on the calibration using a selected test from the \gls[hyper=false]{feba} experiments.
Several posteriors \glspl[hyper=false]{pdf} corresponding to different calibration schemes were formulated and directly sampled from using an MCMC ensemble sampler. 
Different resulting sets of samples were propagated through all the \glsentryshort{trace} models of the \gls[hyper=false]{feba} tests with boundary conditions different than the conditions of the test used for calibration.

The results of different calibration schemes corresponded to different level of trade-off between \emph{informativeness} (the width of the prediction uncertainty band) and the \emph{calibration score} (consistency with the experimental data and whether it is covered by the uncertainty band).
This trade-off was apparent particularly for the schemes with and without model bias term and the scheme with bias but excluding a strongly correlated parameter.
The scheme without bias resulted in the most reduction of the prior uncertainty for most of the important parameters, in which the nominal \glsentryshort{trace} parameter values sometimes laid outside the posterior uncertainty interval.  
The posterior uncertainties associated with the scheme resulted in predictions with the highest informativeness and the lowest calibration scores across \gls[hyper=false]{feba} tests.
The scheme with bias resulted in a more modest reduction of the prior uncertainty of the parameters, keeping the nominal \glsentryshort{trace} parameter values within the uncertainty interval, but exhibited strong correlation for some of the parameters.
The corresponding prediction uncertainties, in turn, gave a better calibration score while having similar level of informativeness.
It could be argued that the relatively worse calibration scores for the scheme with and without bias, in comparison to  that of the prior, was due to the too narrow posterior uncertainties for the former and due to the correlation in the posterior uncertainties for the latter.
As the calibration was conducted based only on one \gls[hyper=false]{feba} test, this suggested a symptom of overfitting, which was stronger for the former than the latter.
Therefore, in the case of limited calibration data, it might be prudent to consider instead the scheme with bias but excluding a strongly correlated parameter, whose calibration scores were consistently high across \gls[hyper=false]{feba} tests albeit with relatively lower informativeness compared to the two previous schemes.

Through these series of applications on the TRACE model of FEBA, the proposed methodology to quantify the uncertainty of the parameters in the physical model of TH system codes based on experimental data have been successfully demonstrated. 

\vfill

\textsc{keywords}:
\glsfirst[hyper=false]{th},
reflood,
\gls[hyper=false]{trace} code,
\glsfirst[hyper=false]{uq},
\glsfirst[hyper=false]{gsa},
\glsfirst[hyper=false]{gp} metamodel,
Bayesian calibration

\vfill

\clearpage

\begin{otherlanguage}{ngerman}
\pdfbookmark[1]{Zusammenfassung}{Zusammenfassung}
\chapter*{Zusammenfassung}
Kurze Zusammenfassung des Inhaltes in deutscher Sprache\dots 
\end{otherlanguage}

\endgroup			

\vfill